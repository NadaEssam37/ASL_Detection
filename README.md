# ASL_Detection
Knowledge base
The implemented ASL detection system functions through Python programming and deep learning methods in its knowledge base. The system functions to detect hand gestures from ASL then generate corresponding linguistic output. The algorithm receives training through hand gesture images which contain American Sign Language alphabets. Users can construct educational tools and accessibility applications for hard of hearing people when using this technology. Users can also design gesture-controlled interfaces with it.

Features:

1Image-based ASL letter recognition

2-Deep learning model built with TensorFlow/Kera

3-Real-time prediction support (optional via webcam)

4-Training visualization with accuracy/loss plots

5-Dataset preprocessing and augmentation

6-Supports classification of 26 alphabets (A-Z)

Model Details:

1-Architecture: CNN (e.g., Conv2D + MaxPooling + Dense layers)

2-Framework: TensorFlow/Keras

3-Input shape: 64x64 or 128x128 images (depending on dataset)

4-Output: Softmax layer with 26 classes

Datasets: https://www.kaggle.com/datasets/namanmanchanda/american-sign-language-model-99-accuracy
